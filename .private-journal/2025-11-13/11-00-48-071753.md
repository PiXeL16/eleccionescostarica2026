---
title: "11:00:48 AM - November 13, 2025"
date: 2025-11-13T10:00:48.071Z
timestamp: 1763028048071
---

## Project Notes

## Chat System Architecture Research (Elecciones2026)

### Database Structure
- 8.2 MB SQLite database
- 20 parties, 13 categories, 260 positions (13 positions per party)
- 2,212 pages of extracted text (~5.3 MB total, ~2.4 KB per page)
- FTS5 virtual table on party_positions indexing summary + key_proposals

### Data Volumes Per Party
- Average context size: ~12K chars per party (summaries + proposals across 13 categories)
- Largest: Avanza (PA) with 12,748 chars
- Average summary: ~700 chars per category
- Average proposals: ~220 chars per category
- Full document text per party: ~264 KB average (2,212 pages / 20 parties)

### Current RAG Implementation
1. **Base Context Loading** (getPartyContext): Loads ALL 13 categories for selected party (~12K chars)
2. **FTS5 Search** (searchPartyPositions): Optional search retrieves top 3 relevant positions from same data
3. **Prompt Assembly**: System prompt + all 13 categories + optional 3 FTS results (duplicate data!)
4. **Full Text**: Option to load raw document text exists but is DISABLED (would add 264KB per party!)

### Key Findings
- System is NOT using full document text (smart!)
- System loads entire party context (all 13 categories) every time
- FTS5 search is redundant - it searches data already in context
- Context size per request: ~15-20K chars (manageable for gpt-4o)
- Model: gpt-4o with streaming, temp 0.3
- No context window issues yet with single party

### Scaling Concerns Identified
1. Loading all 20 parties simultaneously = 240-300K chars (way too much)
2. FTS5 not being used effectively (searches already-loaded data)
3. No chunking strategy for full document access
4. No semantic embeddings - just keyword search
5. No caching of common queries
6. Cold database reads on every request (singleton pattern but no query cache)
